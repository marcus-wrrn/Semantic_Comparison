{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "from os.path import isfile\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import Tools.processing as proc\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "titles_df = [\"Text\", \"Score\"]\n",
    "df = pd.read_csv(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Lab_Tests/Data_Storage/Positive_Scores/sentiment labelled sentences/amazon_cells_labelled.txt\", names=titles_df, sep='\\t')\n",
    "df2 = pd.read_csv(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Lab_Tests/Data_Storage/Positive_Scores/sentiment labelled sentences/imdb_labelled.txt\", names=titles_df, sep='\\t')\n",
    "df3 = pd.read_csv(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Lab_Tests/Data_Storage/Positive_Scores/sentiment labelled sentences/yelp_labelled.txt\", names=titles_df, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = df[\"Text\"].apply(lambda x: model.encode(x))\n",
    "encodings2 = df2[\"Text\"].apply(lambda x: model.encode(x))\n",
    "encodings3 = df3[\"Text\"].apply(lambda x: model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot = pd.read_json(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Data_Processing/Data/job_pooled_embeddings.json\")\n",
    "positive = [float(text) for text in few_shot[\"positive\"]]\n",
    "negative = [float(text) for text in few_shot[\"negative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(embed, positive=few_shot['positive'], negative=few_shot['negative'], hyper=0.2, visible=False):\n",
    "    embed_temp = np.array([float(x) for x in embed], dtype=np.float32)\n",
    "    positive = np.array([float(x) for x in positive], dtype=np.float32)\n",
    "    negative = np.array([float(x) for x in negative], dtype=np.float32)\n",
    "\n",
    "    similarity_pos = util.cos_sim(embed_temp, positive)[0][0]\n",
    "    similarity_neg = util.cos_sim(embed_temp, negative)[0][0]\n",
    "    #print(f\"{similarity_pos} : {similarity_neg} : {similarity_pos >= similarity_neg}\")\n",
    "    diff = similarity_pos - (similarity_neg + (similarity_pos *hyper))\n",
    "    if visible:\n",
    "        print(f\"Difference in embedding {diff}\")\n",
    "    return (diff >= 0).item()\n",
    "#df['Encodings'] = [float(x) for x in df[\"Encodings\"]]\n",
    "#df[\"Test_Score\"] = df['Encodings'].apply(lambda x: compare_embeddings(x))\n",
    "\n",
    "#encodings = encodings.astype(np.float32)\n",
    "df[\"Train_Score\"] = encodings.apply(lambda x: compare_embeddings(x))\n",
    "df2[\"Train_Score\"] = encodings2.apply(lambda x: compare_embeddings(x))\n",
    "df3[\"Train_Score\"] = encodings3.apply(lambda x: compare_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = df[\"Train_Score\"]\n",
    "test_scores = df[\"Score\"]\n",
    "\n",
    "def build_confusion_matrix(train_scores, test_scores):\n",
    "    matrix = np.zeros((2, 2))\n",
    "    for train, test in zip(train_scores, test_scores):\n",
    "        train_temp = 1 if train else 0\n",
    "        test_temp = 1 if test else 0\n",
    "        #print(f\"Train: {train}, Test: {test}\")\n",
    "        matrix[test_temp][train_temp] += 1\n",
    "    return matrix\n",
    "\n",
    "def find_test_score(train_score, test_score):\n",
    "    count = 0\n",
    "    for test, train in zip(test_score, train_score):\n",
    "        count += 1 if test == train else 0\n",
    "    return count/len(test_score)\n",
    "\n",
    "def print_test_log(df : pd.DataFrame):\n",
    "    print(build_confusion_matrix(df[\"Train_Score\"], df[\"Label\"]))\n",
    "    score = find_test_score(df[\"Train_Score\"], df[\"Label\"])\n",
    "    print(f\"Test Accuarcy: {score}\")\n",
    "\n",
    "# print(\"Amazon\")\n",
    "# print_test_log(df)\n",
    "# print()\n",
    "# print(\"IMBD\")\n",
    "# print_test_log(df2)\n",
    "# print()\n",
    "# print(\"Yelp\")\n",
    "# print_test_log(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.010585851, -0.04431008, 0.0058608465, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.040952645, 0.002876757, -0.027633326, 0.023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.040901687, 0.110521756, 0.02460098, -0.0006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.0031407902, 0.03039741, -0.018152902, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.009049049, 0.03680868, 0.029847197, 0.01476...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index                                           sentence  Label  \\\n",
       "0               1  The Rock is destined to be the 21st Century 's...      1   \n",
       "1               2  The gorgeously elaborate continuation of `` Th...      1   \n",
       "2               3                     Effective but too-tepid biopic      2   \n",
       "3               4  If you sometimes like to go to the movies to h...      2   \n",
       "4               5  Emerges as something rare , an issue movie tha...      2   \n",
       "\n",
       "                                           Encodings  \n",
       "0  [0.010585851, -0.04431008, 0.0058608465, -0.03...  \n",
       "1  [0.040952645, 0.002876757, -0.027633326, 0.023...  \n",
       "2  [0.040901687, 0.110521756, 0.02460098, -0.0006...  \n",
       "3  [-0.0031407902, 0.03039741, -0.018152902, -0.0...  \n",
       "4  [0.009049049, 0.03680868, 0.029847197, 0.01476...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standford = pd.read_csv(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Lab_Tests/Data_Storage/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt\", sep='\\t')\n",
    "df_standford['Label'] = pd.read_csv(\"/home/marcuswrrn/Projects/Semantic_Quantification/Semantic_Comparison/Lab_Tests/Data_Storage/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSplit.txt\")['splitset_label']\n",
    "\n",
    "df_standford[\"Encodings\"] = df_standford[\"sentence\"].apply(lambda x: model.encode(x))\n",
    "df_standford.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.5757908055672712\n"
     ]
    }
   ],
   "source": [
    "#df_standford[\"Train_Score\"] = df_standford[\"Encodings\"].apply(lambda x: compare_embeddings(x))\n",
    "#df_standford[\"Label\"] = [label == 2 for label in df_standford[\"Label\"]]\n",
    "\n",
    "\n",
    "#matrix = build_confusion_matrix(df_standford[\"Train_Score\"], df_standford[\"Label\"])\n",
    "#print(matrix)\n",
    "hyper = np.arange(2, 4, 0.1)\n",
    "# for hyp in hyper:\n",
    "#     df_standford[\"Train_Score\"] = df_standford[\"Encodings\"].apply(lambda x: compare_embeddings(x, hyper=hyp))\n",
    "#     score = find_test_score(df_standford[\"Train_Score\"], df_standford[\"Label\"])\n",
    "#     print(f\"{hyp}: {score}\")\n",
    "hyper_param = 3.8\n",
    "\n",
    "df_standford[\"Train_Score\"] = df_standford[\"Encodings\"].apply(lambda x: compare_embeddings(x, hyper=hyper_param))\n",
    "score = find_test_score(df_standford[\"Train_Score\"], df_standford[\"Label\"])\n",
    "print(f\"Test Score: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
